{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca7b88a5-41ad-413c-8960-3d420c0bd2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5392f7f9-6514-4e07-a0af-db833e9a8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fed61f7c-ce5a-4197-9477-42acfb74db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\"\"The general problem of simulating (or creating) intelligence has \n",
    "been broken into subproblems. These consist of particular traits or capabilities\n",
    "that researchers expect an intelligent system to display. The traits described\n",
    "below have received the most attention and cover the scope of AI research\"\"\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686dc097-7abb-4799-9a0e-9a1eba8e4244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'general',\n",
       " 'problem',\n",
       " 'of',\n",
       " 'simulating',\n",
       " '(',\n",
       " 'or',\n",
       " 'creating',\n",
       " ')',\n",
       " 'intelligence',\n",
       " 'has',\n",
       " 'been',\n",
       " 'broken',\n",
       " 'into',\n",
       " 'subproblems',\n",
       " '.',\n",
       " 'These',\n",
       " 'consist',\n",
       " 'of',\n",
       " 'particular',\n",
       " 'traits',\n",
       " 'or',\n",
       " 'capabilities',\n",
       " 'that',\n",
       " 'researchers',\n",
       " 'expect',\n",
       " 'an',\n",
       " 'intelligent',\n",
       " 'system',\n",
       " 'to',\n",
       " 'display',\n",
       " '.',\n",
       " 'The',\n",
       " 'traits',\n",
       " 'described',\n",
       " 'below',\n",
       " 'have',\n",
       " 'received',\n",
       " 'the',\n",
       " 'most',\n",
       " 'attention',\n",
       " 'and',\n",
       " 'cover',\n",
       " 'the',\n",
       " 'scope',\n",
       " 'of',\n",
       " 'AI',\n",
       " 'research']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = word_tokenize(word)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dacf65eb-4a39-4aca-b989-3cd0d703cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "139bb697-3587-4366-a067-a1311faa490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d767bf82-e75e-4664-8161-e80d1481dbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The general problem of simulating (or creating) intelligence has \\nbeen broken into subproblems.',\n",
       " 'These consist of particular traits or capabilities\\nthat researchers expect an intelligent system to display.',\n",
       " 'The traits described\\nbelow have received the most attention and cover the scope of AI research']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b01a9b-4f90-44e2-b8af-6ead8d9db02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ec13b18-f6c9-4f28-84ae-4b12b51a677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\"\"The general problem of simulating (or creating) intelligence has \n",
    "been broken into subproblems. These consist of particular traits or capabilities\n",
    "that researchers expect an intelligent system to display. The traits described\n",
    "below have received the most attention and cover the scope of AI research\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "358ac6cc-a7bb-44d7-a319-1ada1870967d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('general', 'JJ'),\n",
       " ('problem', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('simulating', 'VBG'),\n",
       " ('(', '('),\n",
       " ('or', 'CC'),\n",
       " ('creating', 'VBG'),\n",
       " (')', ')'),\n",
       " ('intelligence', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('broken', 'VBN'),\n",
       " ('into', 'IN'),\n",
       " ('subproblems', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('These', 'DT'),\n",
       " ('consist', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('particular', 'JJ'),\n",
       " ('traits', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('capabilities', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('researchers', 'NNS'),\n",
       " ('expect', 'VBP'),\n",
       " ('an', 'DT'),\n",
       " ('intelligent', 'JJ'),\n",
       " ('system', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('display', 'VB'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('traits', 'NNS'),\n",
       " ('described', 'VBN'),\n",
       " ('below', 'IN'),\n",
       " ('have', 'VBP'),\n",
       " ('received', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('attention', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('cover', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('scope', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('AI', 'NNP'),\n",
       " ('research', 'NN')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = word_tokenize(word)\n",
    "\n",
    "p = pos_tag(post)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8699044c-ec9a-41b8-8922-a366a2f682dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\"\"The general problem of simulating (or creating) intelligence has \n",
    "been broken into subproblems. These consist of particular traits or capabilities\n",
    "that researchers expect an intelligent system to display. The traits described\n",
    "below have received the most attention and cover the scope of AI research\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da861577-7bd7-4947-8e69-da403a62cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b0961a8-4c70-4420-b057-5b969db4e9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "stop = list(punctuation) + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0d265f3-302d-4e11-b2ee-518c4a1e2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c922d985-5977-4880-be4f-0f2126e8f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wor = word_tokenize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f214586-d80f-4c75-ba35-f8b7cbac3bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'general', 'problem', 'simulating', 'creating', 'intelligence', 'broken', 'subproblems', 'These', 'consist', 'particular', 'traits', 'capabilities', 'researchers', 'expect', 'intelligent', 'system', 'display', 'The', 'traits', 'described', 'received', 'attention', 'cover', 'scope', 'AI', 'research']\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i in wor:\n",
    "    if i not in stop:\n",
    "        result.append(i)\n",
    "print(result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "befb8cb5-57f8-4270-8963-814a1ed05968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "069eb35d-36be-45a7-867d-fdfdb582ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancaster = LancasterStemmer()\n",
    "lancaster.stem(\"changing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40954ae0-5281-4fea-825e-c6d4365ba7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e06e6b09-044e-4eaf-a2d4-1e85fef9f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20781b71-c924-4eba-8917-c5223b098da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.fit_transform(result).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e0db1-5672-448d-ba7e-ac56c2675a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
